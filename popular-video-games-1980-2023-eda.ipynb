{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\">Popular Video Games EDA</h1>\n\n<div style=\"text-align:center;\">\n    <img src=\"https://i.imgur.com/sDrZ07n.jpg\" width=800 alt=\"project-banner\">\n</div>","metadata":{"id":"gNjtp85_lsfQ"}},{"cell_type":"markdown","source":"# Introduction \n\nVideo games have become an increasingly popular form of entertainment in recent years, with the industry experiencing tremendous growth and success. Since the release of the first commercial video game, \"Computer Space,\" in 1971, the industry has continued to evolve and expand, with new technologies and platforms constantly being introduced.\n\nToday, video games are played by people of all ages and backgrounds, and the gaming community has grown to be a vibrant and passionate group of individuals. The rise of online gaming has allowed gamers to connect and play with others from all over the world, creating a global community that is constantly evolving and growing.\n\n\n### In this project, \n\nWe will be exploring a dataset of popular video games dating from 1980 to 2023, including \n- Release dates. \n- Number of playes.\n- Number of active players. \n\nThe dataset also includes information about the platforms on which the games were released, the genres they belong to, and other relevant details.\n\nWe will be analyzing this dataset to gain insights into various aspects of the video game industry, including \n\n- The popularity of different genres. \n- The trend of games rating over time (release date). \n- The level of engagement of players with games. \n\nAdditionally, we will be exploring the phenomenon of \"backlogging,\" which refers to the practice of keeping a list of games that one has yet to play or finish.\n\nBy delving into this rich dataset, we hope to uncover interesting trends and patterns in the world of video games, and gain a deeper understanding of the gaming community and industry as a whole. So, join us on this exciting journey as we explore the world of video games through data analysis!\n\n# [Data Source](https://www.kaggle.com/datasets/arnabchaki/popular-video-games-1980-2023)\n\nThis dataset contains a list of video games dating from 1980 to 2023, it also provides things such as release dates, user review rating, and critic review rating.\n\nNot only can you find the popular games mentioned here but also the obscure indie ones which we have forgotten in time!\n\nBacklogged is a video game collection website mixed with social elements to focus on bringing your gaming profile to life. Create a free account to get started on logging the games you've played, and then rating and reviewing as you go! Go into detail with logging platforms, time played, and even a daily journal to keep track your daily gaming progress with playthroughs. It's all tailored to how much you want to log, so that your profile fits you. Then outside of that you can create lists of games, friend other users, follow their activities, and so much more!","metadata":{"id":"QDyHEbO8mXZh"}},{"cell_type":"markdown","source":"# Importing installing Libraries","metadata":{"id":"x4XyKOiimf8o"}},{"cell_type":"code","source":"# Importing pandas for data analysis and manipulation\nimport pandas as pd              \n# Importing numpy for numerical computations\nimport numpy as np               \n# Importing seaborn for data visualization\nimport seaborn as sns            \n# Importing pyplot from matplotlib for data visualization\nimport matplotlib.pyplot as plt  \n# Importing pyplot from matplotlib.dates for dates manipulation\nimport matplotlib.dates as mdates\n# Importing tqdm for progress bars in loops\nfrom tqdm.notebook import tqdm   \n\n# Importing warnings module to handle warning messages\nimport warnings                 \n\n# Setting the max columns to be shown by pandas to 500\npd.options.display.max_columns = None\n\n# Set the float format to display numbers with two decimal places\npd.options.display.float_format = '{:.0f}'.format\n\n# To ignore all warnings generated by the program\nwarnings.filterwarnings(\"ignore\")  \n# Setting seaborn style to white\nsns.set_style(\"white\")            ","metadata":{"id":"2YkpX1L3ms2j","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-15T07:10:40.555128Z","iopub.execute_input":"2023-06-15T07:10:40.555637Z","iopub.status.idle":"2023-06-15T07:10:40.563548Z","shell.execute_reply.started":"2023-06-15T07:10:40.555602Z","shell.execute_reply":"2023-06-15T07:10:40.562296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading in and inspecting the data","metadata":{"id":"YGgCfEiJmXkW"}},{"cell_type":"code","source":"# Reading in the dataset\ndf = pd.read_csv(\"/kaggle/input/popular-video-games-1980-2023/games.csv\")","metadata":{"id":"VgKfvtUaliW0","execution":{"iopub.status.busy":"2023-06-15T07:10:40.586408Z","iopub.execute_input":"2023-06-15T07:10:40.587178Z","iopub.status.idle":"2023-06-15T07:10:40.646537Z","shell.execute_reply.started":"2023-06-15T07:10:40.587138Z","shell.execute_reply":"2023-06-15T07:10:40.645158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking a look at a sample from the dataset\ndf.sample(2)","metadata":{"id":"VgKfvtUaliW0","execution":{"iopub.status.busy":"2023-06-15T07:10:40.648391Z","iopub.execute_input":"2023-06-15T07:10:40.648788Z","iopub.status.idle":"2023-06-15T07:10:40.668373Z","shell.execute_reply.started":"2023-06-15T07:10:40.648757Z","shell.execute_reply":"2023-06-15T07:10:40.667038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing the `df_courses` columns \nfor col in df.columns.to_list():\n    print(col)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:40.670280Z","iopub.execute_input":"2023-06-15T07:10:40.670691Z","iopub.status.idle":"2023-06-15T07:10:40.682376Z","shell.execute_reply.started":"2023-06-15T07:10:40.670659Z","shell.execute_reply":"2023-06-15T07:10:40.681021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the dataset Metadata\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:40.684369Z","iopub.execute_input":"2023-06-15T07:10:40.684749Z","iopub.status.idle":"2023-06-15T07:10:40.707635Z","shell.execute_reply.started":"2023-06-15T07:10:40.684718Z","shell.execute_reply":"2023-06-15T07:10:40.706449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking for duplicates and null values","metadata":{}},{"cell_type":"code","source":"# Printing the number of duplicate values\ndup_count = df.duplicated().sum()\n\nprint(f\"There are {dup_count} duplicate values in the dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:40.748947Z","iopub.execute_input":"2023-06-15T07:10:40.750242Z","iopub.status.idle":"2023-06-15T07:10:40.769864Z","shell.execute_reply.started":"2023-06-15T07:10:40.750199Z","shell.execute_reply":"2023-06-15T07:10:40.768588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing the number of null values\nnull_count = df.isnull().sum()\n\n# Filtering out columns that ONLY has NUll values \nnull_count[null_count != 0]","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:40.775395Z","iopub.execute_input":"2023-06-15T07:10:40.775835Z","iopub.status.idle":"2023-06-15T07:10:40.790065Z","shell.execute_reply.started":"2023-06-15T07:10:40.775802Z","shell.execute_reply":"2023-06-15T07:10:40.788292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Observations For Data Cleaning and Preprocessing :\n---\n\n- The column `'Unnamed: 0'` seems to be an extra index column (probably left over from the data scrapping process.), it should be removed.\n\n- Columns names are not consistent in their naming format, which might cause confusion and type errors.\n\n- The (`Team`, `Number of Reviews`, `Summary`, `Reviews`) are not relevant to the analysis we are going to conduct.\n\n- The naming of the (`Plays` and `playing`) columns is not descriptive and confusing.\n\n- The columns that **should be presenting numerical values uses** a 'nK' format to present numbers in thousands and they are in object (string) date-type.\n\n- The `release date` column is **not in date time format**.\n\n- There are **0** duplicated values.\n\n- The `Rating` column has **13 missing values**.\n","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":" # Data Cleaning and Preprocessing :","metadata":{"id":"Gp0rQV2pmma5"}},{"cell_type":"markdown","source":"### Defining utility functions.","metadata":{}},{"cell_type":"code","source":"def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Rename columns in a DataFrame to lowercase with underscores instead of spaces.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame containing the columns to be renamed.\n\n    Returns\n    -------\n    pd.DataFrame\n        The DataFrame with renamed columns.\n    \"\"\"\n\n    # Use list comprehension to create a new list of column names with spaces replaced by underscores and all lowercase letters\n    new_columns = [col.lower().replace(\" \", \"_\") for col in df.columns]\n\n    # Use the pandas DataFrame rename() method to rename the columns using the new column names list\n    df = df.rename(columns=dict(zip(df.columns, new_columns)))\n\n    return df\n\n\n\ndef drop_columns(df: pd.DataFrame, cols_to_drop: list = None, \n                 idx_to_drop: list = None) -> pd.DataFrame:\n    \"\"\"\n    Drops the specified columns from a pandas DataFrame and returns a new DataFrame with the columns removed.\n    \n    Args:\n    - df: A pandas DataFrame.\n    - cols_to_drop: (Optional) A list of column names to drop from the DataFrame.\n    - idx_to_drop: (Optional) A list of row indices to drop from the DataFrame.\n    \n    Returns:\n    - A new pandas DataFrame with the specified columns and/or rows removed.\n    \n    Example:\n    \n    ```\n    df = drop_columns(df, cols_to_drop=['column1', 'column2'], [3, 4])\n    df = drop_columns(df, idx_to_drop=['column1.index', 'column2.index'], [3, 4])\n\n    ```\n    \"\"\"\n    # Create a copy of the original DataFrame\n    new_df = df.copy()\n\n    # Drop the specified columns from the DataFrame\n    if cols_to_drop is not None:\n        new_df = new_df.drop(columns=cols_to_drop)\n\n    # Drop the specified rows from the DataFrame, if any\n    if idx_to_drop is not None:\n        new_df = new_df.drop(index=idx_to_drop)\n\n    return new_df\n\n\ndef convert_str_num_to_int(df: pd.DataFrame, col_names: list) -> pd.DataFrame:\n    \"\"\"\n    Converts string numerical values in a dataframe to int.\n\n    Parameters:\n        df (pandas.DataFrame): The dataframe to convert.\n        col_names (list): A list of column names containing string numerical values.\n\n    Returns:\n        pandas.DataFrame: The modified dataframe.\n    \"\"\"\n    \n    # Taking a copy of the provided dataframe\n    new_df = df.copy()\n    \n    # Looping over the column names list\n    for col in col_names:\n        # Replace 'K' with '000'\n        new_df[col] = new_df[col].str.replace(\"K\", \"000\")\n\n        # Multiply the values by 1000 to handle decimal values correctly\n        new_df[col] = new_df[col].map(lambda x: int(float(x) * 1000) if '.' in x else int(x))\n\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:40.826900Z","iopub.execute_input":"2023-06-15T07:10:40.827265Z","iopub.status.idle":"2023-06-15T07:10:40.838724Z","shell.execute_reply.started":"2023-06-15T07:10:40.827239Z","shell.execute_reply":"2023-06-15T07:10:40.837165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping the extra index column \"Unamed: 0\" and the irrelevant columns (Team, Number of Reviews, Summary, Reviews) ","metadata":{}},{"cell_type":"code","source":"# Defining the columns to drop\ncols_names = [\"Unnamed: 0\", \"Team\", \"Reviews\", \"Summary\", \"Number of Reviews\", \"Times Listed\"]\n\n# Calling the drop columns function\ndf = drop_columns(df, cols_names)\n\n# Checking the results\ndf.head()","metadata":{"id":"ER0LUdbMmseU","execution":{"iopub.status.busy":"2023-06-15T07:10:40.855854Z","iopub.execute_input":"2023-06-15T07:10:40.856271Z","iopub.status.idle":"2023-06-15T07:10:40.873620Z","shell.execute_reply.started":"2023-06-15T07:10:40.856240Z","shell.execute_reply":"2023-06-15T07:10:40.872319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing the `Release date` column to datetime date type","metadata":{}},{"cell_type":"code","source":"# df[\"Release Date\"] = pd.to_datetime(df[\"Release Date\"]) !#=> Error: ParserError: Unknown string format: releases on TBD\n\n# Taking a look at the Release Date column  \ncond = df[\"Release Date\"] == \"releases on TBD\"\n\n# Filtering the dataset\ndf[cond]","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:40.899450Z","iopub.execute_input":"2023-06-15T07:10:40.899905Z","iopub.status.idle":"2023-06-15T07:10:40.917683Z","shell.execute_reply.started":"2023-06-15T07:10:40.899872Z","shell.execute_reply":"2023-06-15T07:10:40.916243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When attempting to change the `Release Date` column to a datetime data type, a `ParserError` occurred with the message \"Unknown string format: releases on TBD\". After investigating the issue, I found that three games in the dataset had a value of **\"releases on TBD\"** instead of a valid date format in the `Release Date` column.\n\n\nAs Deltarune and Death Stranding 2 have not been released yet, **their missing release dates are understandable.** However, as these missing values are **not useful for our analysis**, these games will be dropped from the dataset.\n\nThe third game with a missing release date was Elden Ring: Shadow of the Erdtree, which was released on February 28, 2023. Although this game is popular, **its data is not useful in this dataset due to the missing Release Date value**. Therefore, it will also be dropped from the dataset.","metadata":{}},{"cell_type":"markdown","source":"### Dropping the 3 rows with the `releases on TBD` value in the `Release Date` column.","metadata":{}},{"cell_type":"code","source":"# Dropping rows using their index from the bool filter\ndf = drop_columns(df, idx_to_drop=df[cond].index)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:40.999546Z","iopub.execute_input":"2023-06-15T07:10:41.000332Z","iopub.status.idle":"2023-06-15T07:10:41.007124Z","shell.execute_reply.started":"2023-06-15T07:10:41.000292Z","shell.execute_reply":"2023-06-15T07:10:41.005995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Changing the `Release Date` Column again after fixing the error\ndf[\"Release Date\"] = pd.to_datetime(df[\"Release Date\"])\n\n# Checking\ndf[\"Release Date\"].dtype","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.021575Z","iopub.execute_input":"2023-06-15T07:10:41.021953Z","iopub.status.idle":"2023-06-15T07:10:41.191960Z","shell.execute_reply.started":"2023-06-15T07:10:41.021924Z","shell.execute_reply":"2023-06-15T07:10:41.190640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing the columns name to lower case and replacing spaces with '_' for consistency.","metadata":{}},{"cell_type":"code","source":"# Using the `clean_column_names` utility function to rename the columns. \ndf = clean_column_names(df)\n\n# Checking the results\ndf.head()","metadata":{"id":"Wg-Vb-oJmuhw","execution":{"iopub.status.busy":"2023-06-15T07:10:41.194684Z","iopub.execute_input":"2023-06-15T07:10:41.195556Z","iopub.status.idle":"2023-06-15T07:10:41.214890Z","shell.execute_reply.started":"2023-06-15T07:10:41.195487Z","shell.execute_reply":"2023-06-15T07:10:41.213292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing the names of the `plays` and `playing` columns to more descriptive names","metadata":{}},{"cell_type":"code","source":"# Defining the rename mapper {old name: new name}\nrename_mapper = {\"plays\":\"no_of_plays\", \"playing\":\"active_players\"}\n\n# Renaming the columns\ndf.rename(columns=rename_mapper, inplace=True)\n\n# Checking the results\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.216633Z","iopub.execute_input":"2023-06-15T07:10:41.217066Z","iopub.status.idle":"2023-06-15T07:10:41.235512Z","shell.execute_reply.started":"2023-06-15T07:10:41.217025Z","shell.execute_reply":"2023-06-15T07:10:41.234234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Numerical Columns\n\nColumns that contain numerical values in the dataset are in string data type (Object) and are formated in thousands using the 'K' symbol, to handle this we will use the `convert_str_num_to_int` utility function to replace the 'K' symbol with '000' and remove any dot '.' then changing the type from (object) to int.","metadata":{"id":"smiEOy_6musy"}},{"cell_type":"code","source":"# Defining the list of columns to unpack the numbers and convert them into int data type.\nnumerical_cols = [\"no_of_plays\", \"active_players\", \"backlogs\", \"wishlist\"]\n\n# Using the utility function to handle the string (object) numerical values and unpack the 'K'  symbol to thousands\ndf = convert_str_num_to_int(df, numerical_cols)\n\n# Checking the results\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.237968Z","iopub.execute_input":"2023-06-15T07:10:41.238323Z","iopub.status.idle":"2023-06-15T07:10:41.271130Z","shell.execute_reply.started":"2023-06-15T07:10:41.238296Z","shell.execute_reply":"2023-06-15T07:10:41.270097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the data types of the numerical columns\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.272286Z","iopub.execute_input":"2023-06-15T07:10:41.272639Z","iopub.status.idle":"2023-06-15T07:10:41.280927Z","shell.execute_reply.started":"2023-06-15T07:10:41.272603Z","shell.execute_reply":"2023-06-15T07:10:41.279582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping `Null` values ","metadata":{}},{"cell_type":"code","source":"# Dropping null values from the dataframe\ndf.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.283078Z","iopub.execute_input":"2023-06-15T07:10:41.283608Z","iopub.status.idle":"2023-06-15T07:10:41.296322Z","shell.execute_reply.started":"2023-06-15T07:10:41.283562Z","shell.execute_reply":"2023-06-15T07:10:41.294991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)\n\n---\n\nIn this section we will be analyzing this dataset to gain insights into various aspects of the video game industry, including : \n\n1. The popularity of different genres. \n\n    1.1. What is the most popular game in each genre. \n    \n2. The trend of games rating over time (release date). \n\n3. The level of engagement of players with popular games. \n\n4. Correlation between backlogging, rating and wishlist variables.","metadata":{"id":"F4DLc9c7mvR9"}},{"cell_type":"markdown","source":"## 1. The popularity of different genres. \n\nTo calculate the popularity of different genres, we are going to follow these steps :\n\n1. Split the `genres` column values on the ',' and create dummy variables representing each genre using pandas `get_dummies()` method\n\n2. Sum the occurrences of each genre and sort the values by descending order to get the most popular first.\n\n3. Plot the top 10 most popular video games genre.","metadata":{}},{"cell_type":"code","source":"# Replacing '[', ']', and \"'\" characters in the genres column with nothing\ndf[\"genres\"] = df[\"genres\"].str.replace('[\\[\\]\\'\\\"]', \"\")\n\n# Creating a binary matrix of genre values for each game\ngenres = df[\"genres\"].str.get_dummies(\",\")\n\n# Summing the occurrences of each genre across all games\npopularity = genres.sum().sort_values(ascending=False)\n\n# Printing the popularity of each genre\npopularity.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.299895Z","iopub.execute_input":"2023-06-15T07:10:41.300337Z","iopub.status.idle":"2023-06-15T07:10:41.341693Z","shell.execute_reply.started":"2023-06-15T07:10:41.300303Z","shell.execute_reply":"2023-06-15T07:10:41.340202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the Top 10 Most Popular Video Games Genres ","metadata":{}},{"cell_type":"code","source":"# Setting the plot's figure size\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# Plotting the horizontal bar chart\nsns.barplot(x=popularity[:10].values, y=popularity[:10].index, palette=\"Blues_r\", ax=ax)\n\n# Adding labels showing the popularity of each genre\nfor i, v in enumerate(popularity[:10].values):\n    ax.text(v + 130 / 2, i, str(f\"{v} Games\"), color=\"black\", ha=\"center\", va=\"center\")\n\n# Setting the title and axis labels\nax.set_title(\"Top 10 Popular Video Game Genres\", fontsize=15, pad=15)\nax.set_xlabel(\"\")\nax.set_ylabel(\"\")\n\n# Removing the x-axis tick labels\nax.set_xticklabels([])\n\n# Increasing the fontsize of the y-axis tick labels\nax.tick_params(axis=\"y\", labelsize=11)\n\n# Removing the spines from the right and top sides of the plot\nsns.despine(right=True, top=True, bottom=True)\n\n# Showing the plot\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-15T07:10:41.342737Z","iopub.execute_input":"2023-06-15T07:10:41.343097Z","iopub.status.idle":"2023-06-15T07:10:41.671302Z","shell.execute_reply.started":"2023-06-15T07:10:41.343066Z","shell.execute_reply":"2023-06-15T07:10:41.670556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1. What is the most popular game in each genre. \n---\n\n#### To Calculate the most popular game in each video game we are going to ues the following approach :\n\n1. First, we will convert the `popularity` `Series` to a `DataFrame` with a single column named `'popularity'` containing the popularity values.\n\n2. Next, we will merges this `DataFrame` with the game data `DataFrame` (`df`) on the `'genres'` column. This adds a new `'popularity'` column to the game data containing the popularity values for each game.\n\n3. Then, we group the merged data by the `'genres'` column using the `groupby` method. This creates a `GroupBy` object with one group for each unique value in the `'genres'` column.\n\n4. After that, we define a function named `get_most_pop_game` that takes a `DataFrame` containing data for a group of games as input and returns the title of the most popular game in that group. The function does this by getting the row with the highest value in the `'popularity'` column and returning the value in its `'title'` column.\n\n5. Finally, we apply this function to each group in the `GroupBy` object using the `apply` method. This returns a new `Series` object containing the title of the most popular game in each genre.\n\n---\n\n#### Resources :\n- [Find the max value of a column and return the corresponding row values - Stackoverflow.](https://stackoverflow.com/questions/15741759/find-maximum-value-of-a-column-and-return-the-corresponding-row-values-using-pan#:~:text=Assuming%20df%20has%20a%20unique%20index%2C%20this%20gives,so%20df.loc%20may%20return%20more%20than%20one%20row.)\n- [pandas.DataFrame.idxmax - Pandas Documentation.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html)","metadata":{}},{"cell_type":"code","source":"# Converting the popularity to a dataframe\npopularity_df = popularity.to_frame(name=\"popularity\")\n\n# Merging the popularity data with the game data\ndf_pop = df.merge(popularity_df, left_on=\"genres\", right_index=True)\n\n# Grouping the data by genre\ngrouped = df_pop.groupby(\"genres\")\n\n# Defining a function to get the most popular game in each group\ndef get_most_pop_game(group: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Get the most popular game in a group of games.\n\n    This function takes a DataFrame containing data for a group of games and returns a Series containing the \n    data for the most popular game in that group.\n\n    Parameters\n    ----------\n    group : pd.DataFrame\n        A DataFrame containing data for a group of games. \n        Must have a column named 'popularity' containing the popularity values for each game.\n\n    Returns\n    -------\n    pd.Series\n        A Series containing the data for the most popular game in the input group.\n    \"\"\"\n\n    # Getting the row with the highest popularity value\n    most_popular_game = group.loc[group[\"popularity\"].idxmax()]\n    \n    # Returning the title of the most popular game\n    return most_popular_game[\"title\"]\n\n# Applying the function to the grouped dataframe and saving the result (series) into a variable\nmost_popular_game = grouped.apply(get_most_pop_game)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.672347Z","iopub.execute_input":"2023-06-15T07:10:41.672694Z","iopub.status.idle":"2023-06-15T07:10:41.693737Z","shell.execute_reply.started":"2023-06-15T07:10:41.672667Z","shell.execute_reply":"2023-06-15T07:10:41.692200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the series into a dataframe, reseting the index and rename the columns \n## to present the most popular game in each video game genre.\nmost_popular_game.to_frame().reset_index() \\\n                 .rename({\"genres\":\"Game Genre\", 0:\"Most Popular Game\"}, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:41.697333Z","iopub.execute_input":"2023-06-15T07:10:41.698966Z","iopub.status.idle":"2023-06-15T07:10:41.723821Z","shell.execute_reply.started":"2023-06-15T07:10:41.698915Z","shell.execute_reply":"2023-06-15T07:10:41.722326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. The trend of games rating over time (release date).\n---\n\n#### To analyis the change in the trend of games rating over time (release date), we are going to use the `rating` and the `release_year` columns.\n\n- The `rating` column is going to be our indicator of how successfully a game is, represented on the x-axis. \n\n- The `release_year` is going to be our time-line (trend) to see the changes of video games ratings over time, represented on the y-axis.","metadata":{}},{"cell_type":"code","source":"# Extracting the release year from the release_date column\ndf[\"release_year\"] = df[\"release_date\"].dt.year\n\n# Grouping the data by release year and calculate the average rating for each year\nyearly_avg_rating = df.groupby(\"release_year\")[\"rating\"].mean().reset_index()\n\n# Setting the plot size\nplt.figure(figsize=(15, 5))\n\n# Plotting the average rating by release year using Seaborn\nsns.lineplot(data=yearly_avg_rating, x=\"release_year\", y=\"rating\")\n\n# Despining the plot from the top and left\nsns.despine(top=True, right=True)\n\n# Adding a descriptive title to the plot\nplt.title(\"Average Game Rating by Release Year\", fontsize=16, pad=15)\n\n# Increasing the padding space between the title, x-label and y-label and the plot\nplt.xlabel(\"\")\nplt.ylabel(\"Average Rating\", labelpad=15, fontsize=15)\n\n# Increasing the font-size of the x-axis and y-axis ticks\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\n# Adding horizontal lines to indicate the maximum and minimum values on the y-axis\nplt.axhline(y=yearly_avg_rating[\"rating\"].max(), color=\"green\", linestyle=\"--\")\nplt.axhline(y=yearly_avg_rating[\"rating\"].min(), color=\"red\", linestyle=\"--\")\n\n# Showing the plot\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-15T07:10:41.725526Z","iopub.execute_input":"2023-06-15T07:10:41.725963Z","iopub.status.idle":"2023-06-15T07:10:42.079452Z","shell.execute_reply.started":"2023-06-15T07:10:41.725916Z","shell.execute_reply":"2023-06-15T07:10:42.078434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">From 1980 through the 1990s, the average rating of video games experienced significant fluctuations, with a notable decline in the late 1980s. However, starting in the 2000s, the average rating has become more stable and consistent. \n\nThis change over time could be due to advancements in technology and game design, evolving consumer preferences, and increased competition. These factors have led to an overall increase in the quality of games and their average ratings.","metadata":{}},{"cell_type":"markdown","source":"## 3. The level of engagement of players with games. \n---\n\n#### To calculate the level of engagement of players with game we are going to thake the following approach :\n\n1. First, we will remove the rows from the DataFrame that have a value of 0 in the `active_players` column. This is done to avoid division by zero when calculating the average number of plays per active player.\n\n2. Next, we will calculates the average number of plays per active player for each game by dividing the `no_of_plays` column by the `active_players` column. The result is rounded to the nearest integer and stored in a new column named `avg_plays_per_player`.\n\n3. Then we sort the data by the `avg_plays_per_player` column in descending order to show the games with the highest average number of plays per active player at the top.\n\n4. Finally, we display the top 5 games with the highest average number of plays per active player.\n","metadata":{}},{"cell_type":"code","source":"# Removing rows with a value of 0 in the active_players column\ndf_engagement = df[df[\"active_players\"] != 0]\n\n# Calculating the average number of plays per active player for each game\ndf_engagement[\"avg_plays_per_player\"] = round(df_engagement[\"no_of_plays\"] / df_engagement[\"active_players\"])\n\n# Sortting the data by average number of plays per active player in descending order\ndf_engagement = df_engagement.sort_values(by=\"avg_plays_per_player\", ascending=False)\n\n# Displaying the top 5 games with the highest average number of plays per active player\ndf_engagement.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:42.080853Z","iopub.execute_input":"2023-06-15T07:10:42.081623Z","iopub.status.idle":"2023-06-15T07:10:42.104204Z","shell.execute_reply.started":"2023-06-15T07:10:42.081582Z","shell.execute_reply":"2023-06-15T07:10:42.102953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the plot's figure size\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# Creating a horizontal bar plot showing the average number of plays per active player for the top 10 games\nsns.barplot(data=df_engagement.head(10), x=\"avg_plays_per_player\", y=\"title\", palette=\"Blues_r\")\n\n# Adding labels showing the popularity of each genre\nfor i, v in enumerate(df_engagement[\"avg_plays_per_player\"].head(10).values):\n    ax.text(v + 220 / 2, i, str(round(v)), color=\"black\", ha=\"center\", va=\"center\")\n\n# Setting the title and axis labels\nax.set_title(\"Top 10 games with the highest engagement.\", fontsize=15, pad=30)\nax.set_xlabel(\"\")\nax.set_ylabel(\"\")\n\n# Removing the x-axis tick labels\nax.set_xticklabels([])\n\n# Increasing the fontsize of the y-axis tick labels\nax.tick_params(axis=\"y\", labelsize=11)\n\n# Removingpines from the right and top sides of the plot\nsns.despine(right=True, top=True, bottom=True)\n\n# Showing the plot\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-15T07:10:42.107435Z","iopub.execute_input":"2023-06-15T07:10:42.108544Z","iopub.status.idle":"2023-06-15T07:10:42.481915Z","shell.execute_reply.started":"2023-06-15T07:10:42.108478Z","shell.execute_reply":"2023-06-15T07:10:42.480765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Correlation between backlogging, rating and wishlist variables. \n---","metadata":{}},{"cell_type":"markdown","source":"#### Let's first plot a correlation heat map of the dataset ","metadata":{}},{"cell_type":"code","source":"# Calculating the correlation matrix\ncorr_matrix = df.corr()\n\n# Setting up the figure size\nfig, ax = plt.subplots(figsize=(15, 5))\n\n# Creating the heatmap\nsns.heatmap(corr_matrix, annot=True, cmap=\"Blues\", annot_kws={\"size\": 12}, ax=ax)\n\n# Setting up the title\nax.set_title(\"Correlation Heatmap\", fontsize=20, pad=25)\n\n# Setting the x-axis and y-axis ticks sizes\nax.tick_params(axis=\"both\", labelsize=12)\n\n# Showing the plot\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-15T07:10:42.483764Z","iopub.execute_input":"2023-06-15T07:10:42.484716Z","iopub.status.idle":"2023-06-15T07:10:42.993540Z","shell.execute_reply.started":"2023-06-15T07:10:42.484665Z","shell.execute_reply":"2023-06-15T07:10:42.992626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From observing the correlation heatamp, we can see that :\n\n- There's a **strong correlation** between backlogs and wishlist.\n- There's some correlation between rating and backlogs.","metadata":{}},{"cell_type":"markdown","source":"###  3.1 Correlation between backlogging and wishlist. ","metadata":{}},{"cell_type":"code","source":"# Grouping the data by the 'wishlist' column and calculating the mean of the 'backlogs' column for each group\nwishlist_backlog = df.groupby(\"wishlist\")[\"backlogs\"].mean().reset_index()\n\n# Renaming the columns for clarity\nwishlist_backlog.columns = [\"Wishlist\", \"Average Backlogs\"]","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:42.994806Z","iopub.execute_input":"2023-06-15T07:10:42.995340Z","iopub.status.idle":"2023-06-15T07:10:43.002682Z","shell.execute_reply.started":"2023-06-15T07:10:42.995310Z","shell.execute_reply":"2023-06-15T07:10:43.001728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the plot's figure size\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# plotting the scatterplot\nax = sns.scatterplot(data=wishlist_backlog, x=\"Wishlist\", y=\"Average Backlogs\", s=50)\n\n# Despine the plot from the right and top\nsns.despine(ax=ax, top=True, right=True)\n\n# Add a descriptive title and increase its size and add padding\nax.set_title(\"Correlation between Wishlist and Backlogs\", fontsize=20, pad=25)\n\n# Increase the size of the x-axis and y-axis ticks\nax.tick_params(axis=\"both\", labelsize=12)\n\n# Increase the size of the x-axis and y-axis labels and add paddings\nax.set_xlabel(\"Wishlist\", fontsize=15, labelpad=20)\nax.set_ylabel(\"Backlogs\", fontsize=15, labelpad=20)\n\n# Show the plot\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-15T07:10:43.004203Z","iopub.execute_input":"2023-06-15T07:10:43.004592Z","iopub.status.idle":"2023-06-15T07:10:43.624065Z","shell.execute_reply.started":"2023-06-15T07:10:43.004560Z","shell.execute_reply":"2023-06-15T07:10:43.622944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">The scatter plot reveals a strong correlation between the 'Wishlist' and 'Backlogs' variables. This is plausible because people who have added a game to their wishlist are likely to have access to it but may not have started playing it yet.","metadata":{}},{"cell_type":"markdown","source":"###  3.2 Correlation between backlogging and rating. ","metadata":{}},{"cell_type":"code","source":"# Grouping the data by the 'rating' column and calculating the mean of the 'backlogs' column for each group\nrating_backlogs = df.groupby(\"rating\")[\"backlogs\"].mean().reset_index()\n\n# Renaming the columns for clarity\nrating_backlogs.columns = [\"Rating\", \"Average Backlogs\"]","metadata":{"execution":{"iopub.status.busy":"2023-06-15T07:10:43.625593Z","iopub.execute_input":"2023-06-15T07:10:43.625930Z","iopub.status.idle":"2023-06-15T07:10:43.633410Z","shell.execute_reply.started":"2023-06-15T07:10:43.625902Z","shell.execute_reply":"2023-06-15T07:10:43.632586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the plot's figure size\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# plotting the scatterplot\nax = sns.scatterplot(data=rating_backlogs, x=\"Rating\", y=\"Average Backlogs\", s=50)\n\n# Despine the plot from the right and top\nsns.despine(ax=ax, top=True, right=True)\n\n# Add a descriptive title and increase its size and add padding\nax.set_title(\"Correlation between Rating and Backlogs\", fontsize=20, pad=25)\n\n# Increase the size of the x-axis and y-axis ticks\nax.tick_params(axis=\"both\", labelsize=15)\n\n# Increase the size of the x-axis and y-axis labels and add paddings\nax.set_xlabel(\"Rating\", fontsize=15, labelpad=20)\nax.set_ylabel(\"Backlogs\", fontsize=15, labelpad=20)\n\n# Show the plot\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-15T07:10:43.636038Z","iopub.execute_input":"2023-06-15T07:10:43.638422Z","iopub.status.idle":"2023-06-15T07:10:44.042073Z","shell.execute_reply.started":"2023-06-15T07:10:43.638381Z","shell.execute_reply":"2023-06-15T07:10:44.040932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">The correlation between the 'Rating' and 'Backlogs' variables appears to be positive. As the average number of backlogs increases, so does the rating. This may be due to people gaining access to games with high ratings but not starting them.","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n\nMy analysis of popular video games from 1980 to 2023 revealed several key insights. We found that the most popular video game genres are **Adventure**, followed by RPG, Platform, and Shooter. Within these genres, some of the most popular games include **Metal Gear Solid 2: Sons of Liberty** (Adventure), Chrome Dino (Arcade), Devil May Cry (Brawler), and Mario Party Superstars (Card & Board Game).\n\nI also observed that the average rating of video games experienced **significant fluctuations from 1980 through the 1990s**, with a notable decline in the late 1980s. However,** starting in the 2000s, the average rating has become more stable and consistent**.\n\nIn terms of player engagement, I found that **Fruit Ninja Classic** had the highest level of engagement, followed by Slither.io, Happy Wheels, and Ms. Pac-Man.\n\nOur analysis also revealed a strong correlation between the 'Wishlist' and 'Backlogs' variables. **This suggests that people who have added a game to their wishlist are likely to have access to it but may not have started playing it yet**. Furthermore, we found that **games with high ratings and high wishlist counts tend to have the most backlogged players**.\n\n---\n\n## Findings Summary\n---\n\n1. The most popular video game genres are Adventure, followed by RPG, Platform, and Shooter.\n\n2. Some of the most popular games within these genres include Metal Gear Solid 2: Sons of Liberty (Adventure), Chrome Dino (Arcade), Devil May Cry (Brawler), and Mario Party Superstars (Card & Board Game).\n\n3. The average rating of video games experienced significant fluctuations from 1980 through the 1990s but has become more stable and consistent since the 2000s.\n\n4. Fruit Ninja Classic had the highest level of player engagement, followed by Slither.io, Happy Wheels, and Ms. Pac-Man.\n\n5. There is a strong correlation between the 'Wishlist' and 'Backlogs' variables.\n\n6. Games with high ratings and high wishlist counts tend to have the most backlogged players.","metadata":{"id":"dHPOHyb8mzge"}},{"cell_type":"markdown","source":"# Acknowledgement \n\n- [Find the max value of a column and return the corresponding row values - Stackoverflow.](https://stackoverflow.com/questions/15741759/find-maximum-value-of-a-column-and-return-the-corresponding-row-values-using-pan#:~:text=Assuming%20df%20has%20a%20unique%20index%2C%20this%20gives,so%20df.loc%20may%20return%20more%20than%20one%20row.)\n\n- [pandas.DataFrame.idxmax - Pandas Documentation.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html)\n\n- [Barplot data labels inspiration - (Stackoverflow).](https://stackoverflow.com/questions/59213470/how-to-annotate-text-on-horizontal-seaborn-barplot)\n\n- [Banner Design - Canva.](https://canva.com/)\n","metadata":{}}]}